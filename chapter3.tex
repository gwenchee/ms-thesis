\chapter{Methods}
\label{chap:3}
In this chapter, the \glspl{NFCSim} used in this work 
, \Cyclus and DYMOND, and the new capabilities developed for 
\glspl{NFCSim} are described. 
The new capabilities are: 
(1) demand-driven deployment capabilities in \Cyclus, 
(2) sensitivity analysis capabilities for DYMOND, and
(3) sensitivity analysis capabilities for \Cyclus. 

\section{\Cyclus}
\Cyclus is an agent-based nuclear fuel cycle simulation framework 
\cite{huff_fundamental_2016}. 
In \Cyclus, each entity (i.e. Region, Institution, or Facility) in 
the fuel cycle is an agent. 
Region agents represent geographical or political areas that institution
and facility agents can be grouped into. 
Institution agents control the 
deployment and decommission of facility agents 
and represents legal operating organizations such as a 
utility, government, etc. \cite{huff_fundamental_2016}. 
Facility agents represent nuclear fuel cycle facilities. 
\Cycamore \cite{carlsen_cycamore_2014}
provides facility agents to represent process physics of various 
components in the nuclear fuel cycle (e.g. mine, fuel enrichment 
facility, reactor). 
The \Cycamore reactor model uses externally-calculated 
recipes for fresh and spent fuel compositions. 
The mass flows and inventories are recorded at an agent-level
and individual isotopes are tracked. 

% Describe the agent-based model and flexibility
Two of \Cyclus' main design objectives are user customization and 
extensibility. 
These objectives are achieved through \Cyclus' modularity, 
open architecture, and agent interchangeability. 
The modularity and open architecture provides users with a 
platform to develop custom facilities with their chosen fidelity 
and capabilities. 
Agent interchangeability facilitates setting up of custom fuel 
cycles and direct comparisons of alternative modeling methodologies 
and facility concepts \cite{huff_fundamental_2016}. 
\Cyclus' input file has an XML file format and the output file is 
a SQL database. 

\section{DYMOND}
DYMOND \cite{yacout_modeling_2005} is a \gls{NFCSim} developed 
at \gls{ANL}. 
It is built using the AnyLogic simulation software with 
Microsoft Excel templates for data input and output. 
The major inputs to this code are reactor and fuel cycle 
characteristics, and time-dependent power demand 
\cite{feng_standardized_2016}.   
The code calls ORIGEN \cite{bell_origen_1973} during the simulation 
to conduct reactor depletion calculations. 
The mass flows and inventories are recorded at a system-level
and individual isotopes are tracked. 
DYMOND's main design objective is ease of understanding its 
behavior and variables. 

In DYMOND, reactor facilities are automatically deployed to 
meet a user-defined power demand and the user can define 
the targeted shares of energy for up to five reactor types. 
The user also defines the fuel loading model used to calculate 
reactor spent fuel compositions, the type of reprocessing 
technology that is used for each reactor type, and the length 
of used fuel cooling time etc. 
In DYMOND, the user must define the deployment schedule for 
the reprocessing plants and the cooling pools and storage pools 
are all assumed to have infinite capacities. 
DYMOND does not have demand-driven deployment capabilities for 
supporting fuel cycle facilities. 

The difference between \Cyclus and DYMOND is that \Cyclus uses 
agent-based modeling for all facilities and mass flows, 
whereas DYMOND uses fleet-based modeling for all facilities and 
mass flows with exception of reactor facilities. 
\Cyclus has the advantage of flexibility and customization, 
and DYMOND has the advantage of ease of use. 

\section{Demand driven deployment capability in \Cyclus (\deploy)}
In 2016, there was a push to understand and evaluate the 
transition from the initial EG01 state to promising future 
end-states \cite{feng_standardized_2016}.
Previously in \Cyclus, reactor facilities are automatically 
deployed to meet a user-defined power demand. 
However, it is up to the user to define a deployment scheme of 
supporting facilities to ensure that there is no gap in the supply 
chain that results in idle reactor capacity. 
To avoid this issue, users 
have to set infinite capacities for the support facilities, 
but this is an inaccurate representation of reality. 
Another option is to manually calculate a suitable deployment 
schedule. 
It is straightforward to manually determine a deployment scheme 
for a once-through fuel cycle, however, it is difficult to effectively 
implement for complex closed fuel cycle scenarios.  
Therefore, to successfully conduct analysis of the time-dependent 
closed fuel cycle transition
analyses, it is necessary to develop \gls{NFCSim} tools to  
automate setting up of transition scenarios. 
Therefore, Demand-Driven Cycamore Archetypes project
(NEUP-FY16-10512) was initiated to develop demand-driven deployment 
capabilities in \Cyclus.
This capability is added as a \Cyclus Institution
agent that deploys facilities to meet the front-end and back-end 
fuel cycle demands based on a user-defined commodity demand. 
This demand-driven deployment capability is called 
\deploy. 

\subsection{\deploy framework}
\label{sec:d3ploy}
In \Cyclus, developers have the option to design 
agents using C++ or Python. 
The \deploy \texttt{Institution} agent was 
implemented in Python to enable the use of 
well developed time series forecasting Python packages. 

In a \Cyclus simulation, at every timestep, \deploy 
predicts supply and demand of each commodity for the next time 
step. 
If there is an undersupply of any commodity based 
on the predicted values, \deploy deploys facilities to meet 
the predicted demand.  
Figure \ref{fig:flow} shows the logic flow of \deploy 
at every timestep. 

\begin{figure}[]
    \centering
    \caption{\deploy logic flow at every timestep in \Cyclus \cite{chee_demonstration_2019}.}
    \label{fig:flow}
    \begin{tikzpicture}[node distance=2.5cm]
        \tikzstyle{every node}=[font=\large]
        \node (Start) [bblock] {\textbf{Start of timestep ($t$).}};
        \node (Predict) [bblock, below of=Start] {\textbf{Calculate \\ $D_p(t+1)$ and $S_p(t+1)$ for a commodity}};
        \node (IsThere) [oblock, below of=Predict]{\textbf{$U(t+1) = S_p(t+1)-D_p(t+1)$}};
        \node (Deploy) [sbblock, below of=IsThere, xshift = -3.5cm]{\textbf{Deployment \\ of facility}};
        \node (NoDeploy) [sbblock, right of=Deploy, xshift = 3.5cm]{\textbf{No Deployment} };
        \node (All) [oblock, below of=Deploy, xshift = 3.5cm] {\textbf{Is this done for all commodities?}};
        \node (End) [bblock, below of=All] {\textbf{Proceed to next timestep.}};
        
        \draw [arrow] (Start) -- (Predict); 
        \draw [arrow] (Predict) -- (IsThere);
        \draw [arrow] (IsThere) -- node[anchor=east] {$U(t+1) <$ buffer} (Deploy);
        \draw [arrow] (IsThere) -- node[anchor=west] {$U(t+1) \geq$ buffer} (NoDeploy);
        \draw [arrow] (Deploy) -- (All);
        \draw [arrow] (NoDeploy) -- (All);
        \draw [arrow] (All) -- node[anchor=west] {yes} (End);
        \draw [arrow] (All) -- ([shift={(-3.9cm,0.7cm)}]All.south west)-- node[anchor=east] {no} ([shift={(-3.9cm,-0.85cm)}]Predict.north west)--(Predict);
        \draw [arrow] (End) |-([shift={(3cm,-0.5cm)}]End.south east)-- ([shift={(3cm,0.5cm)}]Start.north east)-|(Start);
    \end{tikzpicture}
\end{figure}

\deploy's main objective is to minimize
undersupply of power. 
The sub-objectives are : (1) to minimize the number of time 
steps of undersupply or under capacity of any 
commodity, (2) to minimize excessive oversupply of all commodities.
This is a reflection of reality in which it is important to 
never have an undersupply of power on the grid by ensuring power 
plants are never short of fuel, while not 
having excessive oversupply resulting in a burden to store unused 
supplies. 
\glspl{NFCSim} often face power undersupplies at certain time steps 
due to lack of viable fuel, despite having sufficient installed 
reactor capacity.  
Therefore, using \deploy to automatically deploy supporting facilities 
will prevent this from occurring.  

\subsubsection{\textbf{Structure}}
%Description of front end and back end of fuel cycle 
%Demand Driven vs. Supply Driven 
In \deploy, two different institutions control 
front-end and back-end fuel cycle facilities: 
\texttt{DemandDrivenDeploymentInst} and 
\texttt{SupplyDrivenDeploymentInst}, respectively. 
This distinction was made because front-end facilities 
are deployed to meet demand for commodities they produce, 
whereas, back-end facilities are deployed to meet supply for the 
commodities they provide capacity for. 
For example, for front-end facilities, a reactor facility 
demands fuel and \texttt{DemandDrivenDeploymentInst} 
triggers deployment of fuel fabrication facilities to create 
supply, and thus, meeting demand for fuel to prevent undersupply. 
For back-end facilities, the reactor generates spent fuel and 
\texttt{SupplyDrivenDeploymentInst} triggers deployment of 
waste storage facilities to create capacity meeting the supply 
of spent fuel to prevent under capacity. 

\subsubsection{\textbf{Input Variables}}
Table \ref{tab:inputs} lists and gives examples of the input 
variables \deploy accepts. 
Essentially, the user must do the following: 
define the facilities controlled by \deploy and their respective 
capacities, the driving commodity and 
its demand equation, the deployment driving method, and the 
preferred prediction method. 
The user also has the option to define supply/capacity buffers 
for individual commodities, facility preferences, and facility 
constraints. 
The subsequent sections provide an 
in-depth description of the deployment driving methods, buffers, 
facility preferences, and prediction methods. 

\begin{table}[]
    \centering
    \caption{\deploy's required and optional input parameters with examples.}
    \label{tab:inputs}
        \footnotesize
        \begin{tabularx}{\textwidth}{l|LL}
        \hline
            & \textbf{Input Parameter}                                                           & \textbf{Examples}                                                                                                          \\ \hline
            \multirow{5}{*}{\textbf{Required}} & Demand driving commodity                                                           & Power, Fuel, Plutonium, etc.                                                                                                                      \\ \cline{2-3} 
                                                      & Demand equation                                                                    & P(t) = 10000, sin(t), 10000*t                                                                                                                 \\ \cline{2-3} 
                                                      & Facilities it controls                                                             & Fuel Fab, LWR, SFR, Waste repository, etc.                                                                                                      \\ \cline{2-3} 
                                                      & Capacities of the facilities                                                       & 3000 kg, 1000 MW, 50000 kg                                                                                                     \\ \cline{2-3} 
                                                      & Prediction method                                                                  & \begin{tabular}[c]{@{}l@{}}Power: fast fourier transform\\ Fuel: moving average\\ Spent fuel: moving average\end{tabular} \\ \cline{2-3} 
                                                      & Deployment driven by & Installed Capacity/Supply                                                                                                                    \\ \hline
            \multirow{4}{*}{\textbf{Optional}} & Supply/Capacity Buffer type                                                                        & Absolute                                                                                                                  \\ \cline{2-3} 
                                                      & Supply/Capacity Buffer size                                                                        & \begin{tabular}[c]{@{}l@{}}Power: 3000 MW\\ Fuel: 0 kg \\ Spent fuel: 0 kg\end{tabular}                                   \\ \cline{2-3} 
                                                      & Facility preferences                                                               & \begin{tabular}[c]{@{}l@{}}LWR = 100-t\\ SFR = t-100 \end{tabular}          \\ \cline{2-3} 
                                                      & Facility shares                                                             & \begin{tabular}[c]{@{}l@{}}MOX LWR = 85\%\\ SFR = 15\% \end{tabular}          \\ \hline	
                    \end{tabularx}
\end{table}

    \subsubsection{\textbf{Deployment Driving Method}}
    The user has the choice of deploying facilities based on the difference 
    between either predicted demand and supply, or predicted demand and 
    installed capacity. 
    There are two advantages of using installed capacity over predicted 
    supply. 
    First, to prevent over-deployment of facilities with an
    intermittent supply; one example would be reactor
    facilities that have periodic downtimes for refueling. 
    If predicted supply was selected instead of installed capacity, 
    \deploy would deploy surplus reactors during refueling downtimes to 
    meet the temporary power undersupply.
    Second, to prevent infinite deployment of a facility that uses 
    a commodity no longer available in the simulation. 
    For example, in a transition scenario from \glspl{LWR} to \glspl{SFR}, 
    the reprocessing plant that fabricates \gls{SFR} fuel might demand 
    Pu after the existing inventory is depleted 
    and all Pu-generating \glspl{LWR} have already been decommissioned. 
    This will result in \deploy deploying infinite reprocessing 
    facilities in a futile attempt to produce \gls{SFR} fuel, given the lack of Pu.
    This can also be avoided by using \deploy's facility constraint capability 
    (section \ref{sec:constrain})
    to withhold \gls{SFR} deployment until a sizable inventory of Pu 
    is accumulated in the simulation. 
    
    \subsubsection{\textbf{Supply/Capacity Buffer}}
    In \texttt{DemandDrivenDeploymentInst}, the user has the option 
    to provide a supply buffer for each commodity; \deploy will account 
    for the buffer when calculating predicted demand and 
    deploy facilities accordingly.
    In \texttt{SupplyDrivenDeploymentInst} the user has the option 
    to provide a capacity buffer for specific commodities; 
    \deploy will account 
    for the buffer when calculating predicted supply and 
    deploy facilities accordingly.
    For example, the user could set the power commodity's supply buffer 
    to be 2000 MW. 
    If predicted demand is 10000 MW, \deploy will deploy reactor 
    facilities to meet the predicted demand and supply buffer, resulting 
    in a power supply of 12000 MW.  
    The buffer can be defined as a percentage (equation \ref{eq:perc}) 
    or absolute value (equation \ref{eq:abs}). 
    
    \begin{equation}
        \label{eq:perc}
        S_{pwb} = S_{p}*(1+d)
    \end{equation}
    \begin{equation}
        \label{eq:abs}
        S_{pwb} = S_{p}+a
    \end{equation}
    where $S_{pwb}$ is predicted supply/capacity with buffer, 
    $S_p$ is the predicted supply/capacity without buffer, 
    $d$ is the percentage value in decimal form, 
    and $a$ is the absolute value of the buffer. 
    
    Using a combination of this buffer capability alongside the 
    installed capacity deployment driving method in a transition 
    scenario simulation effectively minimizes undersupply of a 
    commodity while avoiding excessive oversupply. 
    This is demonstrated in section \ref{sec:demo}. 
    
    \subsubsection{\textbf{Facility Preference and Share}}
    The user can elect to specify time-dependent preference equations 
    for each facility; if more than one facility can supply the same 
    commodity, \deploy uses these equations to determine which facility 
    to deploy during a commodity shortage. 
    In table \ref{tab:inputs}, 
    the \gls{LWR} reactor has a preference of $100-t$ and the 
    \gls{SFR} reactor has a preference of $t-100$. 
    Thus, the simulation will have a preference to deploy 
    \glspl{LWR} before time step 100 and \glspl{SFR} afterwards. 
    
    The user also has the option to specify percentage-share for facilities 
    that provide the same commodity.   
    In table \ref{tab:inputs}, 
    the \gls{MOX} \gls{LWR} has a share of 85\%, while 
    the \gls{SFR} has a share of 15\%. 
    This constrains \gls{SFR} deployment to 85\% of total power demand 
    and \gls{MOX} \gls{LWR} deployment to 15\% of total power demand.  

    The transition year is selected using the facility 
    preferences, and the sharing capability determines the percentage 
    share of each type of reactor to transition to. 
    Therefore, when \deploy predicts an undersupply of a commodity, 
    it deploys facilities in order of preference, starting at 
    the highest and moving down if the facility percentage share 
    is already met. 
    If the facilities do not have preferences, \deploy 
    will deploy the available facilities to minimize the number of 
    deployed facilities while minimizing oversupply of the commodity.

\subsubsection{\textbf{Prediction Methods}}
\deploy records supply and demand values at each time step for all 
commodities. 
This provides time series data for \deploy's time series 
forecasting methods to predict future supply and demand for each 
commodity.  
Three main method types were investigated: non-optimizing, 
deterministic-optimizing, and stochastic-optimizing
time series forecasting methods.
Non-optimizing methods are techniques that harness 
simple moving average and autoregression concepts that use 
historical data to infer future supply and demand values. 
Deterministic-optimizing and stochastic-optimizing 
methods are techniques 
that use an assortment of more complex time series forecasting 
concepts to predict future supply and demand values. 
Deterministic-optimizing methods give deterministic solutions,
while stochastic-optimizing methods give stochastic solutions. 

Depending on the scenario in question, each forecasting method 
offers its own distinct benefits and disadvantages.
The various methods are compared for each type of simulation 
to determine the most effective prediction method for 
a given scenario.  
The prediction methods will be described in the following 
sections. 

\noindent
\textit{Non-Optimizing Methods}

Non-optimizing methods include: Moving Average (\texttt{MA})
, Autoregressive Moving Average (\texttt{ARMA}), and 
Autoregressive Heteroskedasticity (\texttt{ARCH}). 
The \texttt{MA} method calculates the average of 
a user-defined number of previous entries in a commodity's 
time series and returns it as the predicted value 
(equation \ref{eq:ma}).

\begin{equation}
	\label{eq:ma}
	Predicted\ Value = \frac{V_1+V_2+...+V_n}{n}
\end{equation}

The \texttt{ARMA} method combines moving average and
autoregressive models (equation \ref{eq:arma}).
The first term is a constant, second term is 
white noise, third term is the autoregressive
model, and the fourth term is the moving average
model.
The \texttt{ARMA} method is more accurate than the 
\texttt{MA} method 
because of the inclusion of the autoregressive term. 

\begin{equation}
	\label{eq:arma}
	X_t = c + \epsilon_t + 
	\sum_{i=1}^p\varphi_i X_{t-i} +	
	\sum_{i=1}^q\theta_i\epsilon_{t-i}
\end{equation}

The \texttt{ARCH} method modifies the original moving 
average term (described in equation \ref{eq:arma}). 
This modification makes the \texttt{ARCH} method 
better than the \texttt{ARMA} method for volatile time 
series data \cite{flanagan_methods_2019}. 
The StatsModels \cite{github_community_statsmodels:_2019}
Python package is used to implement \texttt{ARMA} and 
\texttt{ARCH} methods in \deploy. 

\noindent
\textit{Deterministic-Optimizing Methods}

Deterministic methods include: 
Fast Fourier Transform (\texttt{FFT}), 
Polynomial Fit (\texttt{poly}), 
Exponential Smoothing (\texttt{exp-smoothing})
, and Triple Exponential Smoothing (\texttt{holt-winters}). 
The \texttt{FFT} method computes the discrete Fourier transform 
of the time series to predict future demand and supply 
values (equation \ref{eq:fft}).
This method is implemented in \deploy using the 
SciPy \cite{jones_scipy:_2016} Python package. 

\begin{equation}
	\label{eq:fft}
	X_k = \sum_{n=0}^{N-1}x_n e^{-i2\pi kn/N}
\end{equation}

The \texttt{poly} method models the time series data 
with a nth degree (user-defined) polynomial to determine 
future demand and supply values. 
This method was implemented in \deploy using the 
NumPy \cite{developers_numpy_2013} Python package. 
The \texttt{exp-smoothing} and \texttt{holt-winters} 
methods use a weighted average 
of time series data with weights decaying exponentially 
for older time series values \cite{hyndman_forecasting:_2018}
to create a model to determine future demand and supply values. 
The \texttt{exp-smoothing} method excels in 
modeling univariate time series data without trend or seasonality, 
whereas the \texttt{holt-winters} method applies exponential 
smoothing three times resulting in higher accuracy when 
modeling seasonal time series data. 
The StatsModels \cite{github_community_statsmodels:_2019}
Python package was used to implement both of these methods 
in \deploy. 

\noindent
\textit{Stochastic-Optimizing Methods}

There is one stochastic-optimizing method: step-wise 
seasonal method. 
The method was implemented in \deploy by the auto \gls{ARIMA} 
method in the pmdarima \cite{noauthor_pmdarima:_2019}
Python package. 
The \gls{ARIMA} model is a generalization of the \gls{ARMA}
model to make the model fit the time series data better. 
It replaces the time series values with the difference
between consecutive values. 

\section{Sensitivity Analysis Capabilities}
In this work, \Cyclus and DYMOND are coupled with Dakota 
\cite{eldred_dakota_2010} to give the \glspl{NFCSim} \gls{SA}, 
\gls{UQ}, and optimization capabilities. 
The reason for wrapping \Cyclus and DYMOND with Dakota instead of 
other sensitivity analysis tools (Python packages etc.)
is because Dakota is a well supported \gls{SA}, \gls{UQ}, 
and optimization tool that provides a flexible interface between 
analysis codes and iterative system analysis methods 
\cite{turner_virtual_nodate}. 
It has also previously been coupled with other nuclear engineering 
softwares \cite{turner_virtual_nodate,zhang_uncertainty_nodate}. 

The process of coupling with Dakota are similar 
for both \glspl{NFCSim}. 
The coupling is depicted in Figure \ref{fig:dakota-NFC-flow} in which 
Dakota is applied as a wrapper around each of the \glspl{NFCSim}. 
In this work, a Python interface between Dakota and the \glspl{NFCSim}
are developed. 
The Python interface has three functions: 
(1) edit the \gls{NFCSim}'s input file based on Dakota's input values, 
(2) run the simulation with the newly edited \gls{NFCSim} input file, and 
(3) read the \gls{NFCSim}'s output file and returns values of interest 
to the Dakota output file. 
The parameters for the \gls{SA}, \gls{UQ}, or optimization study 
is defined in the Dakota input file. 
The differences in the Python interface between Dakota and each 
\gls{NFCSim} lies in the writing to and reading of 
each of their input and output files. 

\begin{figure}[]
    \centering
    \begin{tikzpicture}[node distance=4.5cm]
        \tikzstyle{every node}=[font=\large]
        \node (one) [sbblock,text width=4cm]{\small Dakota input file};
    \node (two) [bblock, right of=one, xshift = 1cm, text width=5cm]{\scriptsize Python Script\begin{itemize}
        \item Edit NFC code input file with Dakota's inputs 
        \item Run NFC code with new input file 
        \item Read NFC code database for selected output variable
    \end{itemize}};
    \node  (three) [sbblock, xshift = 1cm, right of=two,text width=4cm]{\small Dakota output file};
        
        \draw [arrow] (one) -- (two);
        \draw [arrow] (two) -- (three);
        \draw [arrow] (three) |-([shift={(0cm,-1.5cm)}]three.south west)-- ([shift={(0cm,-1.5cm)}]one.south east)-|(one);
    \end{tikzpicture}
    \caption{Depiction of coupling of Dakota and NFC code}
    \label{fig:dakota-NFC-flow}
\end{figure}

\subsection{Dymond-Dakota Coupling}
% python scripts to parse the excel input and output templates 
In the interface between Dymond and Dakota, the Pywin32 
\cite{hammond_python_2000}
Python package is used to parse the excel input file to 
write to the relevant excel cells according. 
Pywin32 is a thin Python wrapper that enables interaction 
with COM objects \cite{hammond_python_2000}. 
The Pandas \cite{mckinney_pandas:_2011} Python
package is used to analyze the excel output database 
by taking the values of interest and formatting them 
to return to the dakota output file.
The scripts coupling Dymond and Dakota are demonstrated in the 
\texttt{ddwrapper} github repository \cite{ddwrapper_doi_2019}.

\subsection{\Cyclus-Dakota Coupling}
% python scripts + jinja2 for input 
% python scripts + cymetric for output 
In the interface between \Cyclus and Dakota, 
the Jinja2 \cite{ronacher_welcome_2018} Python package is used 
to edit the relevant parts of a \Cyclus' xml input file. 
Jinja2 is a modern and designer-friendly templating 
language for Python. 
The \textsc{Cymetric} \cite{scopatz_cymetric_2015} package is used 
with Python to analyze the \Cyclus output database. 
\textsc{Cymetric} is a general analysis library and tool that was 
created in 2015 to more easily interact with \Cyclus' SQL 
database. 
The scripts coupling \Cyclus and Dakota are demonstrated in the 
\texttt{dcwrapper} github repository \cite{ddwrapper_doi_2019}.

% Add github doi 


